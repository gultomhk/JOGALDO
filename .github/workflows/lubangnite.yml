name: Scrape M3U8 from AxLive

on:
  workflow_dispatch:
  schedule:
    - cron: '*/30 * * * *'  # Setiap 30 menit

permissions:
  contents: write  # Diperlukan agar bisa push map.json

jobs:
  scrape_axlive:
    runs-on: ubuntu-latest

    env:
      AXLIVE_LIVESTREAM_URL: ${{ secrets.AXLIVE_LIVESTREAM_URL }}
      AXLIVE_FEATURED_URL: ${{ secrets.AXLIVE_FEATURED_URL }}
      AXLIVE_LIVESTREAM_SPORT3_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT3_URL }}
      AXLIVE_LIVESTREAM_SPORT4_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT4_URL }}
      AXLIVE_LIVESTREAM_SPORT5_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT5_URL }}
      AXLIVE_LIVESTREAM_SPORT6_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT6_URL }}
      AXLIVE_LIVESTREAM_SPORT7_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT7_URL }}
      AXLIVE_LIVESTREAM_SPORT8_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT8_URL }}
      AXLIVE_LIVESTREAM_SPORT9_URL: ${{ secrets.AXLIVE_LIVESTREAM_SPORT9_URL }}
      AXLIVE_MATCH_BASE_URL: ${{ secrets.AXLIVE_MATCH_BASE_URL }}
      PROXY_BASE_URL: ${{ secrets.PROXY_BASE_URL }}

    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # penting untuk git pull / rebase

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ”§ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dotenv playwright
          playwright install chromium

      - name: ğŸ” Debug environment variables
        run: |
          echo "ğŸ” Menampilkan URL AxLive (aman):"
          for key in AXLIVE_LIVESTREAM_URL AXLIVE_FEATURED_URL AXLIVE_LIVESTREAM_SPORT3_URL \
                     AXLIVE_LIVESTREAM_SPORT4_URL AXLIVE_LIVESTREAM_SPORT5_URL \
                     AXLIVE_LIVESTREAM_SPORT6_URL AXLIVE_LIVESTREAM_SPORT7_URL \
                     AXLIVE_LIVESTREAM_SPORT8_URL AXLIVE_LIVESTREAM_SPORT9_URL \
                     AXLIVE_MATCH_BASE_URL PROXY_BASE_URL
          do
            url="${!key}"
            if [ -n "$url" ]; then
              safe_url=$(echo "$url" | awk -F[/?] '{print $1 "//" $3 $4}')
              echo "  $key -> $safe_url"
            else
              echo "  $key -> Tidak diset"
            fi
          done

      - name: â–¶ï¸ Jalankan skrip scraping
        run: python lubangnite.py

      - name: ğŸ›  Pastikan map.json selalu ada
        run: |
          if [ ! -f map.json ]; then
            echo "{}" > map.json
            echo "ğŸ“„ map.json kosong dibuat sebagai fallback."
          fi

      - name: ğŸ“¤ Commit & Push jika ada perubahan
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add map.json

          if git diff --cached --quiet; then
            echo "â„¹ï¸ Tidak ada perubahan pada map.json. Skip commit dan push."
          else
            echo "âœ… Perubahan terdeteksi. Commit dan push..."
            git commit -m "Update map.json - $(date +'%Y-%m-%d %H:%M:%S')"
            git pull --rebase origin master
            git push origin master
            echo "ğŸš€ Berhasil push ke repository."
